{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06f17437",
   "metadata": {},
   "source": [
    "Example notebook for defining networks and training expert models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8342ec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from keras import initializers\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from keras.metrics import Precision, Recall\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.optimizers.schedules import ExponentialDecay\n",
    "from keras.utils import to_categorical\n",
    "import scipy\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import itertools\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "#Ensuring script directory is correct\n",
    "script_dir = os.path.dirname(os.path.abspath(sys.argv[0]))\n",
    "os.chdir(script_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fe2a89",
   "metadata": {},
   "source": [
    "Necessary Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c45fc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "def build_model(input_dim, layer_neurons, activation='tanh'):\n",
    "    #Setting up generic model inputs based on layers and neurons\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(layer_neurons[0], activation=activation, input_dim=input_dim))\n",
    "    for i in range(1, len(layer_neurons) - 1):\n",
    "        model.add(layers.Dense(layer_neurons[i], activation=activation))\n",
    "    model.add(layers.Dense(layer_neurons[-1], activation='softplus'))\n",
    "    return model\n",
    "\n",
    "def relative_mse(y_true, y_pred):\n",
    "    #Defining MSE loss function\n",
    "    return tf.reduce_mean(tf.square((y_pred - y_true) / (y_true + 1e-6)))\n",
    "\n",
    "def evaluate_metrics(y_test, y_pred, X_test=None, water=False):\n",
    "    #Building evaluation metrics\n",
    "    mape = (1/len(y_test))*np.sum(abs(np.array(y_test)-np.array(y_pred))/(np.array(y_test)))\n",
    "    nmae = (1/np.mean(y_test))*(1/len(y_test))*np.sum(abs(np.array(y_test)-np.array(y_pred)))\n",
    "    rmse = np.sqrt((1/len(y_test))*np.sum((np.array(y_test)-np.array(y_pred))**2))\n",
    "    if water:\n",
    "        #Comment in/out version for ammonium cases\n",
    "        print('NH4 != 0')\n",
    "        unscale_factor = (X_test['NH4+'] + X_test['NH4+']*(X_test['NA+']+X_test['SO42-'] + X_test['NO3-'] + X_test['CL-'])) * (X_test['RH'] / (1 - X_test['RH']))\n",
    "   \n",
    "        y_test_unscaled = np.array(y_test).flatten() * np.array(unscale_factor).flatten()\n",
    "        y_pred_unscaled = np.array(y_pred).flatten() * np.array(unscale_factor).flatten()\n",
    "        mass_error =  (1/(len(y_test_unscaled))) * np.sum((abs((y_test_unscaled*18)-(np.asarray(y_pred_unscaled).reshape(-1)*18)))/((X_test['NH4+']*18)+ X_test['NH4+']*((X_test['NA+']*23) + (X_test['SO42-']*96) + (X_test['NO3-']*62) + (X_test['CL-']*35.5)) + (y_test_unscaled * 18)))\n",
    "\n",
    "        # print('NH4 = 0')\n",
    "        # unscale_factor = (X_test['NA+'] + X_test['NA+']*(X_test['SO42-'] + X_test['NO3-'] + X_test['CL-'])) * (X_test['RH'] / (1 - X_test['RH']))\n",
    "   \n",
    "        # y_test_unscaled = np.array(y_test).flatten() * np.array(unscale_factor).flatten()\n",
    "        # y_pred_unscaled = np.array(y_pred).flatten() * np.array(unscale_factor).flatten()\n",
    "        # mass_error =  (1/(len(y_test_unscaled))) * np.sum((abs((y_test_unscaled*18)-(np.asarray(y_pred_unscaled).reshape(-1)*18)))/((X_test['NA+']*23) + X_test['NA+']*((X_test['SO42-']*96) + (X_test['NO3-']*62) + (X_test['CL-']*35.5)) + (y_test_unscaled * 18)))\n",
    "        return {'RMSE': rmse, 'NMAE': nmae, 'MAPE': mape, 'mass_error': mass_error}\n",
    "    else:\n",
    "        return {'RMSE': rmse, 'NMAE': nmae, 'MAPE': mape}\n",
    "\n",
    "def gaussian_loglik(y_true, y_pred):\n",
    "    #Gaussian loglikelihood\n",
    "    y_true = np.asarray(y_true).ravel()\n",
    "    y_pred = np.asarray(y_pred).ravel()\n",
    "    n = len(y_true)\n",
    "    resid = y_true - y_pred\n",
    "    sigma2 = np.mean(resid**2)\n",
    "    return -0.5 * n * (np.log(2 * np.pi * sigma2) + 1)\n",
    "\n",
    "def logmeanexp(x):\n",
    "    xmax = np.max(x)\n",
    "    return xmax + np.log(np.mean(np.exp(x - xmax)))\n",
    "\n",
    "\n",
    "def train_model(arch, seed, X_trainval, y_trainval, X_test, y_test, batch_size, epochs, patience, \n",
    "                lr_exp_scheduler, filepath, lr_callback = None, water=False):\n",
    "    tf.keras.backend.clear_session()\n",
    "    print(f'Training architecture: {arch}')\n",
    "    set_seeds(seed)\n",
    "    print(f'\\tSeed: {seed}')\n",
    "    #Ammonium present water case\n",
    "    predictors = ['TEMP', 'RH', 'NA+', 'SO42-', 'NO3-', 'CL-']\n",
    "    #Ammonium absent case\n",
    "    #predictors = ['TEMP', 'RH', 'SO42-', 'NO3-', 'CL-']\n",
    "\n",
    "    #Creating train/val spit from the x_trainval\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size = 0.25, shuffle=True, random_state = seed)\n",
    "\n",
    "    #Scaling training, testing data\n",
    "    X_val_copy = X_val.copy()\n",
    "    scalers = {}\n",
    "    for col in ['TEMP', 'RH']:\n",
    "        mean = X_train[col].mean()\n",
    "        std = X_train[col].std(ddof=0)\n",
    "        X_train[col] = (X_train[col] - mean) / std\n",
    "        X_val[col] = (X_val[col] - mean) / std\n",
    "        scalers[col] = (mean, std)\n",
    "    \n",
    "    X_test_copy = X_test.copy()\n",
    "    #Scaling global test data\n",
    "    X_test_scaled = X_test.copy()\n",
    "    for col in ['TEMP', 'RH']:\n",
    "        mean, std = scalers[col]\n",
    "        X_test_scaled[col] = (X_test_scaled[col] - mean) / std\n",
    "    print('\\t\\tConstructing model...')\n",
    "    #model construction\n",
    "\n",
    "    if water:\n",
    "        #Scaling water\n",
    "        # y_train['water_content'] = y_train['water_content']/((X_train['SO42-']+X_train['NO3-']+X_train['CL-']) * ((X_train['RH'])/(1-X_train['RH'])))\n",
    "        # y_val['water_content'] = y_val['water_content']/((X_val['SO42-']+X_val['NO3-']+X_val['CL-']) * ((X_val['RH'])/(1-X_val['RH'])))\n",
    "        # y_test['water_content'] = y_test['water_content']/((X_test_scaled['SO42-']+X_test_scaled['NO3-']+X_test_scaled['CL-']) * ((X_test_scaled['RH'])/(1-X_test_scaled['RH'])))\n",
    "        #model construction\n",
    "        model = build_model(input_dim = len(predictors), layer_neurons=arch)\n",
    "        optimizer = keras.optimizers.legacy.Adam(learning_rate=0.001)\n",
    "        model.compile(optimizer = optimizer, loss = tf.keras.losses.Huber(), metrics=['MeanSquaredError'])\n",
    "    else:\n",
    "        model = build_model(input_dim = len(predictors), layer_neurons=arch)\n",
    "        optimizer = keras.optimizers.legacy.Adam(learning_rate=lr_exp_scheduler)\n",
    "        model.compile(optimizer = optimizer, loss = relative_mse, metrics=['MeanSquaredError'])\n",
    "\n",
    "\n",
    "    #Callbacks\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=patience,\n",
    "        min_delta=0.00005,\n",
    "        mode='min',\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    if lr_callback:\n",
    "        lr_cb = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "    print('\\t\\tTraining...')\n",
    "    #Training\n",
    "    start = time.time()\n",
    "    if water:\n",
    "        history = model.fit(X_train.loc[:,predictors], y_train, validation_data=(X_val.loc[:,predictors], y_val), batch_size=batch_size, epochs=epochs, shuffle=True, callbacks=[early_stopping, lr_cb], verbose=0)\n",
    "    else:\n",
    "        history = model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=batch_size, epochs=epochs, shuffle=True, callbacks=[early_stopping], verbose=0)\n",
    "    end = time.time()\n",
    "    elapsed = end-start\n",
    "    print(f'\\t\\tTraining time: {elapsed} seconds')\n",
    "    #Final validation evaluation\n",
    "    print('\\t\\tEvaluating validation set...')\n",
    "    y_val_pred = model.predict(X_val.loc[:,predictors])\n",
    "    if water:\n",
    "        val_metrics = evaluate_metrics(y_val, y_val_pred, X_val_copy, water = True)\n",
    "    else:\n",
    "        val_metrics = evaluate_metrics(y_val, y_val_pred)\n",
    "    print(f'\\t\\t{val_metrics}')\n",
    "    #Final evaluation on test set\n",
    "    print('\\t\\t Evaluating test set')\n",
    "    y_test_pred = model.predict(X_test_scaled.loc[:,predictors])\n",
    "    if water:\n",
    "        test_metrics = evaluate_metrics(y_test, y_test_pred, X_test_copy, water=True)\n",
    "    else:\n",
    "        test_metrics = evaluate_metrics(y_test, y_test_pred)\n",
    "    print(f'\\t\\t{test_metrics}')\n",
    "    #Extract model complexity\n",
    "    total_params = model.count_params()\n",
    "    #Calculate log likelihood\n",
    "    test_loglike = gaussian_loglik(y_test.values, y_test_pred)\n",
    "\n",
    "    results = {\n",
    "        'n_layers': len(arch),\n",
    "        'neurons': arch,\n",
    "        'seed': seed,\n",
    "        'params': total_params,\n",
    "        'val_RMSE': val_metrics['RMSE'],\n",
    "        'val_MAPE': val_metrics['MAPE'],\n",
    "        'val_NMAE': val_metrics['NMAE'],\n",
    "        'test_RMSE': test_metrics['RMSE'],\n",
    "        'test_MAPE': test_metrics['MAPE'],\n",
    "        'test_NMAE': test_metrics['NMAE'],\n",
    "        'test_loglike': test_loglike,\n",
    "        'train_time':elapsed,\n",
    "        'epochs_trained':len(history.history['loss']),\n",
    "        'training_history': history.history\n",
    "    }\n",
    "    if water:\n",
    "        results['val_mass_error'] = val_metrics['mass_error']\n",
    "        results['test_mass_error'] = test_metrics['mass_error']\n",
    "\n",
    "    model_name = f\"arch_{'_'.join(map(str, arch))}_seed_{seed}\"\n",
    "    save_path = os.path.join(script_dir, filepath, model_name)\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    # 1. Save the full model (Best Practice)\n",
    "    model.save(f\"{save_path}/full_model.keras\")\n",
    "\n",
    "    # 2. Save weights and JSON separately (If you specifically need them)\n",
    "    model.save_weights(f\"{save_path}/weights.weights.h5\")\n",
    "    with open(f\"{save_path}/metadata.json\", \"w\") as f:\n",
    "        f.write(model.to_json())\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc512a5",
   "metadata": {},
   "source": [
    "Loading and transforming data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81a205de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading raw data, editing column names and binning liquid + mixed into one class\n",
    "df = pd.read_parquet(f'/Users/jeremyelvander/Desktop/AQRC Research/ml_files/data_procurement/eaim_training_final.parquet')\n",
    "df = df.drop(columns=['n_H2O_g'])\n",
    "df = df.rename(columns={'n_H2O_aq':'water_content'})\n",
    "df['phase'] = df['phase'].replace(2, 0)\n",
    "df['phase'] = df['phase'].replace(3, 0)\n",
    "\n",
    "#Ensuring correct ratio scaling\n",
    "with open('/Users/jeremyelvander/Desktop/AQRC Research/ml_files/new_models/solid_amm_nit_nonzero.pkl', 'rb') as file:\n",
    "    load_model = pickle.load(file)\n",
    "b = load_model.coef_[0]\n",
    "a = np.exp(load_model.intercept_)\n",
    "\n",
    "df['amm_nit_ratio'] = df['amm_nit']/(a * np.exp(b * (1/df['TEMP'])))\n",
    "\n",
    "#Ensuring correct ratio scaling\n",
    "with open('/Users/jeremyelvander/Desktop/AQRC Research/ml_files/new_models/solid_amm_chl_nonzero_NEW.pkl', 'rb') as file:\n",
    "    load_model = pickle.load(file)\n",
    "b = load_model.coef_[0]\n",
    "a = np.exp(load_model.intercept_)\n",
    "\n",
    "df['amm_chl_ratio'] = df['amm_chl']/(a * np.exp(b * (1/df['TEMP'])))\n",
    "\n",
    "df = df[df['amm_nit_ratio'] <= 1.]\n",
    "df = df[df['amm_chl_ratio'] <= 1.]\n",
    "\n",
    "\n",
    "#Building dataset for NH4 = 0 Case\n",
    "df_nh4_zero = df[df['NH4+'] == 0].copy()\n",
    "cols_zero = ['SO42-', 'NO3-', 'CL-']\n",
    "df_nh4_zero['water_content'] = df_nh4_zero['water_content']/((df_nh4_zero['NA+']+df_nh4_zero['SO42-']+df_nh4_zero['NO3-']+df_nh4_zero['CL-']) * ((df_nh4_zero['RH'])/(1-df_nh4_zero['RH'])))\n",
    "df_nh4_zero.loc[:,cols_zero] = df_nh4_zero[cols_zero].div(df_nh4_zero['NA+'], axis=0)\n",
    "df_na = df_nh4_zero.loc[:,'NA+']\n",
    "#df_nh4_zero.drop(columns=['NH4+', 'NA+'], inplace=True)\n",
    "\n",
    "#Building dataset for NH4 =/= 0 case\n",
    "df_nh4_nonzero = df[df['NH4+'] != 0].copy()\n",
    "cols_nonzero = ['NA+', 'SO42-', 'NO3-', 'CL-']\n",
    "df_nh4_nonzero['water_content'] = df_nh4_nonzero['water_content']/((df_nh4_nonzero['NH4+']+df_nh4_nonzero['NA+']+df_nh4_nonzero['SO42-']+df_nh4_nonzero['NO3-']+df_nh4_nonzero['CL-']) * ((df_nh4_nonzero['RH'])/(1-df_nh4_nonzero['RH'])))\n",
    "df_nh4_nonzero.loc[:,cols_nonzero] = df_nh4_nonzero[cols_nonzero].div(df_nh4_nonzero['NH4+'], axis=0)\n",
    "df_nh4 = df_nh4_nonzero.loc[:,'NH4+']\n",
    "#df_nh4_nonzero.drop(columns=['NH4+'], inplace=True)\n",
    "\n",
    "df_nh4_zero.reset_index(drop=True, inplace=True)\n",
    "df_nh4_nonzero.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8581b8b",
   "metadata": {},
   "source": [
    "NH4+ =/= 0 Phase Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29fab0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(scalers, file)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#DELETE ABOVE\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#split for train / test\u001b[39;00m\n\u001b[1;32m     25\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predictors = ['TEMP', 'RH', 'NA+', 'SO42-', 'NO3-', 'CL-']\n",
    "\n",
    "#Setting up training/validation sets\n",
    "X = df_nh4_nonzero.loc[:,predictors]\n",
    "y = df_nh4_nonzero.loc[:,['phase']]\n",
    "\n",
    "#Normalizing temperature and relative humidity\n",
    "scalers = {}\n",
    "for col in ['TEMP', 'RH']:\n",
    "    mean = X[col].mean()\n",
    "    std = X[col].std(ddof=0)\n",
    "    X[col] = (X[col] - mean) / std\n",
    "    scalers[col] = (mean, std)\n",
    "\n",
    "\n",
    "#split for train / test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle=True)\n",
    "\n",
    "#split for val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25)\n",
    "\n",
    "y_train = y_train.astype(int)\n",
    "y_val = y_val.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "#Training model\n",
    "phase_classifier = Sequential()\n",
    "phase_classifier.add(Dense(input_dim = 6, units=32, activation='tanh')) # 16\n",
    "phase_classifier.add(Dense(units=16,activation='tanh'))\n",
    "phase_classifier.add(Dense(units=8,activation='tanh')) #6\n",
    "phase_classifier.add(Dense(units=4,activation='tanh')) #new\n",
    "phase_classifier.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "lr_exp_scheduler = ExponentialDecay(\n",
    "    initial_learning_rate = 0.001,\n",
    "    decay_steps=81973,\n",
    "    decay_rate=0.96,\n",
    "    staircase=False\n",
    ")\n",
    "\n",
    "def focal_loss(gamma=2., alpha=.6):\n",
    "    def loss(y_true, y_pred):\n",
    "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1. - 1e-7)\n",
    "        pt = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n",
    "        return -tf.reduce_mean(alpha * tf.pow(1. - pt, gamma) * tf.math.log(pt))\n",
    "    return loss\n",
    "\n",
    "optimizer = keras.optimizers.legacy.Adam(learning_rate=lr_exp_scheduler)\n",
    "phase_classifier.compile(optimizer = optimizer, loss = focal_loss(), metrics=['binary_crossentropy', 'accuracy', Precision(), Recall()])\n",
    "\n",
    "#Adding early stopping to prevent overfitting\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=40,\n",
    "    min_delta=0.0005,\n",
    "    mode='max',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train['phase'].values)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "history = phase_classifier.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=512, epochs=1000, shuffle=True, \n",
    "class_weight=class_weight_dict, callbacks=[early_stopping])\n",
    "\n",
    "# phase_classifier.save('/Users/jeremyelvander/Desktop/AQRC Research/ml_files/new_models/phase_classifier_nonzero.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a057ea24",
   "metadata": {},
   "source": [
    "NH4+ =/= 0, Liquid/Mix, Ammonium Nitrate Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f29f302",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5_/y_2p6lf540s0fskbmjbhg1qc0000gn/T/ipykernel_27283/1718721625.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  nonzero_liqmix_pp = df_nh4_nonzero[df_nh4_nonzero['phase']==0][df_nh4_nonzero['amm_nit']!=0].copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 51\u001b[0m\n\u001b[1;32m     49\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(scalers, file)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 51\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m#DELETE ABOVE\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m#Load and Process Data\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nonzero_liqmix_pp = df_nh4_nonzero[df_nh4_nonzero['phase']==0][df_nh4_nonzero['amm_nit']!=0].copy()\n",
    "\n",
    "# plt.hist(nonzero_liqmix_pp['amm_nit'], bins=100)\n",
    "# plt.xlabel('Ammonium Nitrate (Units)')\n",
    "# plt.ylabel('Count')\n",
    "# plt.title('Ammonium Nitrate (Raw) - NH4 =/= 0, Liquid/Mix Case')\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "#Loading amm_nit solid case exponential model for data normalization\n",
    "with open('/Users/jeremyelvander/Desktop/AQRC Research/ml_files/new_models/solid_amm_nit_nonzero.pkl', 'rb') as file:\n",
    "    load_model = pickle.load(file)\n",
    "b = load_model.coef_[0]\n",
    "a = np.exp(load_model.intercept_)\n",
    "#Transforming data\n",
    "nonzero_liqmix_pp['amm_nit'] = nonzero_liqmix_pp['amm_nit']/(a * np.exp(b * (1/nonzero_liqmix_pp['TEMP'])))\n",
    "\n",
    "# plt.hist(nonzero_liqmix_pp['amm_nit'], bins=100)\n",
    "# plt.xlabel('Ammonium Nitrate (Units)')\n",
    "# plt.ylabel('Count')\n",
    "# plt.title('Ammonium Nitrate (Scaled) - NH4 =/= 0, Liquid/Mix Case')\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "predictors = ['TEMP', 'RH', 'NA+', 'SO42-', 'NO3-', 'CL-']\n",
    "X = nonzero_liqmix_pp.loc[:,predictors].copy()\n",
    "y = nonzero_liqmix_pp.loc[:,['amm_nit']].copy()\n",
    "\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=4722)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #Load and Process Data\n",
    "    filepath = 'NH4_nonzero/amm_nit/'\n",
    "\n",
    "    architectures = [\n",
    "        (4, 1),\n",
    "        (8, 4, 1),\n",
    "        (16, 8, 1),\n",
    "        (20, 10, 5, 1),\n",
    "        (32, 16, 8, 1),\n",
    "        (64, 32, 16, 1),\n",
    "        (128, 64, 32, 16, 1)\n",
    "    ]\n",
    "    seeds = (1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n",
    "    results = []\n",
    "\n",
    "    batch_size = 512\n",
    "    epochs = 500\n",
    "    patience = 40\n",
    "    lr = 0.0005\n",
    "\n",
    "    #Setup scheduler\n",
    "    decay_steps = int((len(X_trainval)*0.75)/batch_size * 25)\n",
    "    lr_exp_scheduler = ExponentialDecay(\n",
    "        initial_learning_rate = lr,\n",
    "        decay_steps=decay_steps,\n",
    "        decay_rate=0.96,\n",
    "        staircase=False\n",
    "    )\n",
    "\n",
    "\n",
    "    #Run with ProcessPoolExecutor\n",
    "    print(\"Starting Training across multiple processes...\")\n",
    "    with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "        futures = [\n",
    "            executor.submit(train_model, arch, seed, X_trainval, y_trainval, X_test, y_test, \n",
    "                            batch_size, epochs, patience, lr_exp_scheduler, filepath, water=False)\n",
    "            for arch, seed in itertools.product(architectures, seeds)\n",
    "        ]\n",
    "        results = [f.result() for f in futures]\n",
    "\n",
    "    #Save Final Results\n",
    "    df_results = pd.DataFrame(results)\n",
    "\n",
    "    df_results.to_csv('/Users/jeremyelvander/Desktop/AQRC Research/ml_files/model_training/NH4_nonzero/amm_nit/nz_lm_amm_nit_nn.csv')\n",
    "    print(\"All models trained and results saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a272f488",
   "metadata": {},
   "source": [
    "NH4+ =/= 0, Liquid/Mix, Ammonium Chloride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b659530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5_/y_2p6lf540s0fskbmjbhg1qc0000gn/T/ipykernel_27283/367297124.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  nonzero_liqmix_pp = df_nh4_nonzero[df_nh4_nonzero['phase']==0][df_nh4_nonzero['amm_chl']!=0].copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(scalers, file)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 52\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m#DELETE ABOVE\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m#Load and process data and parameters\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#NH4 =/= 0, Liq/Mix, Amm_Chl Network \n",
    "nonzero_liqmix_pp = df_nh4_nonzero[df_nh4_nonzero['phase']==0][df_nh4_nonzero['amm_chl']!=0].copy()\n",
    "\n",
    "# plt.hist(nonzero_liqmix_pp['amm_chl'], bins=100)\n",
    "# plt.xlabel('Ammonium Chloride (Units)')\n",
    "# plt.ylabel('Count')\n",
    "# plt.title('Ammonium Chloride (Raw) - NH4 =/= 0, Liquid/Mix Case')\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "#Loading amm_nit solid case exponential model for data normalization\n",
    "with open('/Users/jeremyelvander/Desktop/AQRC Research/ml_files/new_models/solid_amm_chl_nonzero_NEW.pkl', 'rb') as file:\n",
    "    load_model = pickle.load(file)\n",
    "b = load_model.coef_[0]\n",
    "a = np.exp(load_model.intercept_)\n",
    "#Transforming data\n",
    "nonzero_liqmix_pp['amm_chl'] = nonzero_liqmix_pp['amm_chl']/(a * np.exp(b * (1/nonzero_liqmix_pp['TEMP'])))\n",
    "\n",
    "# plt.hist(nonzero_liqmix_pp['amm_chl'], bins=100)\n",
    "# plt.xlabel('Ammonium Chloride (Units)')\n",
    "# plt.ylabel('Count')\n",
    "# plt.title('Ammonium Chloride (Raw) - NH4 =/= 0, Liquid/Mix Case')\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "predictors = ['TEMP', 'RH', 'NA+', 'SO42-', 'NO3-', 'CL-']\n",
    "X = nonzero_liqmix_pp.loc[:,predictors].copy()\n",
    "y = nonzero_liqmix_pp.loc[:,['amm_chl']].copy()\n",
    "\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=4722)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #Load and process data and parameters\n",
    "    filepath = 'NH4_nonzero/amm_chl/'\n",
    "    architectures = [\n",
    "    (4, 1),\n",
    "    (8, 4, 1),\n",
    "    (16, 8, 1),\n",
    "    (20, 10, 5, 1),\n",
    "    (32, 16, 8, 1),\n",
    "    (64, 32, 16, 1),\n",
    "    (128, 64, 32, 16, 1)\n",
    "    ]\n",
    "    seeds = (1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n",
    "    results = []\n",
    "\n",
    "    batch_size = 512\n",
    "    epochs = 500\n",
    "    patience = 40\n",
    "    lr = 0.0005\n",
    "    #Setup scheduler\n",
    "    decay_steps = int((len(X_trainval)*0.75)/batch_size * 25)\n",
    "    lr_exp_scheduler = ExponentialDecay(\n",
    "        initial_learning_rate = lr,\n",
    "        decay_steps=decay_steps,\n",
    "        decay_rate=0.96,\n",
    "        staircase=False\n",
    "    )\n",
    "    #Run with ProcessPool\n",
    "    print(\"Starting Training across multiple processes...\")\n",
    "    with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "        futures = [\n",
    "            executor.submit(train_model, arch, seed, X_trainval, y_trainval, X_test, y_test, \n",
    "                            batch_size, epochs, patience, lr_exp_scheduler, filepath, water=False)\n",
    "            for arch, seed in itertools.product(architectures, seeds)\n",
    "        ]\n",
    "        results = [f.result() for f in futures]\n",
    "\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "\n",
    "    df_results.to_csv('/Users/jeremyelvander/Desktop/AQRC Research/ml_files/model_training/NH4_nonzero/amm_chl/nz_lm_amm_chl_nn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fc2ccd",
   "metadata": {},
   "source": [
    "NH4+ =/= 0, Liquid/Mix, Water Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a14082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(scalers, file)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m#DELETE ABOVE\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m#Setting up parameters and loading data\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nonzero_liquid_mix = df_nh4_nonzero[df_nh4_nonzero['phase']==0].copy()\n",
    "nonzero_liquid_mix = nonzero_liquid_mix[nonzero_liquid_mix['water_content'] > 0.009]\n",
    "\n",
    "#Building training/validation sets\n",
    "predictors = ['TEMP', 'RH', 'NA+', 'SO42-', 'NO3-', 'CL-']\n",
    "X = nonzero_liquid_mix#.loc[:,predictors]\n",
    "y = nonzero_liquid_mix.loc[:,['water_content']]\n",
    "\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=4722)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #Setting up parameters and loading data\n",
    "    filepath = 'NH4_nonzero/water_content/'\n",
    "\n",
    "    architectures = [\n",
    "    (4, 1),\n",
    "    (8, 4, 1),\n",
    "    (16, 8, 1),\n",
    "    (20, 10, 5, 1),\n",
    "    (32, 16, 8, 1),\n",
    "    (64, 32, 16, 1),\n",
    "    (128, 64, 32, 16, 1)\n",
    "    ]\n",
    "    seeds = (1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n",
    "    results = []\n",
    "\n",
    "    batch_size = 1024\n",
    "    epochs = 500\n",
    "    patience = 40\n",
    "    #Establishing lr callback\n",
    "    lr_callback = True\n",
    "\n",
    "    lr = 0.0005\n",
    "\n",
    "    decay_steps = int((len(X_trainval)*0.75)/batch_size * 25)\n",
    "    lr_exp_scheduler = ExponentialDecay(\n",
    "        initial_learning_rate = lr,\n",
    "        decay_steps=decay_steps,\n",
    "        decay_rate=0.96,\n",
    "        staircase=False\n",
    "    )\n",
    "\n",
    "    #Running with ProcessPool\n",
    "    with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "        futures=[\n",
    "            executor.submit(train_model, arch, seed, X_trainval, y_trainval, X_test, y_test, batch_size, epochs, patience, \n",
    "                    lr_exp_scheduler, filepath, lr_callback=lr_callback, water=True)\n",
    "            for arch, seed in itertools.product(architectures, seeds)\n",
    "        ]\n",
    "        results = [f.result() for f in futures]\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "\n",
    "    df_results.to_csv('/Users/jeremyelvander/Desktop/AQRC Research/ml_files/model_training/NH4_nonzero/water_content/nz_lm_water_content_nn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1dec74",
   "metadata": {},
   "source": [
    "NH4+ = 0, Phase Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa63bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(scalers, file)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#DELETE ABOVE\u001b[39;00m\n\u001b[1;32m     21\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predictors = ['TEMP', 'RH', 'SO42-', 'NO3-', 'CL-']\n",
    "X = df_nh4_zero.loc[:,predictors]\n",
    "y = df_nh4_zero.loc[:,['phase']]\n",
    "\n",
    "scalers = {}\n",
    "for col in ['TEMP', 'RH']:\n",
    "    mean = X[col].mean()\n",
    "    std = X[col].std(ddof=0)\n",
    "    X[col] = (X[col] - mean) / std\n",
    "    scalers[col] = (mean, std)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle=True)\n",
    "\n",
    "#split for val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25)\n",
    "\n",
    "y_train = y_train.astype(int)\n",
    "y_val = y_val.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "phase_classifier = Sequential()\n",
    "phase_classifier.add(Dense(input_dim = 5, units=8, activation='tanh'))\n",
    "phase_classifier.add(Dense(units=3,activation='tanh'))\n",
    "phase_classifier.add(Dense(units=3,activation='tanh'))\n",
    "phase_classifier.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "lr_exp_scheduler = ExponentialDecay(\n",
    "    initial_learning_rate = 0.005,\n",
    "    decay_steps=5156,\n",
    "    decay_rate=0.96,\n",
    "    staircase=False\n",
    ")\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.legacy.Adam(learning_rate=lr_exp_scheduler)\n",
    "phase_classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics=['binary_crossentropy', 'accuracy', Precision(), Recall()])\n",
    "\n",
    "#Adding early stopping to prevent overfitting\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=40,\n",
    "    min_delta=0.0005,\n",
    "    mode='max',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train['phase'].values)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "history = phase_classifier.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=64, epochs=1000, shuffle=True, \n",
    "class_weight=class_weight_dict, callbacks=[early_stopping])\n",
    "\n",
    "# phase_classifier.save('/Users/jeremyelvander/Desktop/AQRC Research/ml_files/new_models/phase_classifier_zero.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048ece2d",
   "metadata": {},
   "source": [
    "NH4+ = 0, Liquid/Mix, Water Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcb6c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(scalers, file)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m#DELETE ABOVE\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m#Establishing parameter input\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "zero_liquid_mix = df_nh4_zero[df_nh4_zero['phase']==0].copy()\n",
    "\n",
    "\n",
    "predictors = ['TEMP', 'RH', 'SO42-', 'NO3-', 'CL-']\n",
    "\n",
    "#Setting up training and test sets\n",
    "X = zero_liquid_mix\n",
    "y = zero_liquid_mix.loc[:,['water_content']]\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=4722)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #Establishing parameter input\n",
    "    filepath = 'NH4_zero/water_content/'\n",
    "\n",
    "    architectures = [\n",
    "        (4, 1),\n",
    "        (8, 4, 1),\n",
    "        (16, 8, 1),\n",
    "        (20, 10, 5, 1),\n",
    "        (32, 16, 8, 1),\n",
    "        (64, 32, 16, 1),\n",
    "        (128, 64, 32, 16, 1)\n",
    "    ]\n",
    "    seeds = (1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n",
    "    results = []\n",
    "\n",
    "    batch_size = 1024\n",
    "    epochs = 500\n",
    "    patience = 40\n",
    "\n",
    "    lr_callback = True\n",
    "\n",
    "    lr = 0.0005\n",
    "\n",
    "    decay_steps = int((len(X_trainval)*0.75)/batch_size * 25)\n",
    "    lr_exp_scheduler = ExponentialDecay(\n",
    "        initial_learning_rate = lr,\n",
    "        decay_steps=decay_steps,\n",
    "        decay_rate=0.96,\n",
    "        staircase=False\n",
    "    )\n",
    "\n",
    "    #Running with processPool\n",
    "    with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "        futures=[\n",
    "            executor.submit(train_model, arch, seed, X_trainval, y_trainval, X_test, y_test, batch_size, epochs, patience, \n",
    "                    lr_exp_scheduler, filepath, lr_callback, water=True)\n",
    "            for arch, seed in itertools.product(architectures, seeds)\n",
    "        ]\n",
    "        results = [f.result() for f in futures]\n",
    "\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results.to_csv('/Users/jeremyelvander/Desktop/AQRC Research/ml_files/model_training/NH4_zero/water_content/z_lm_water_content_nn.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
